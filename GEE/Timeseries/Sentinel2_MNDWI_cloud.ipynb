{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUfHpA2NfCN6/0cicu6iYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LasiJaya24/RS_team_collaboration24/blob/main/MNDWI_Timeseries_Batch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m4fLMTbKmhoH"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import geopandas as gpd\n",
        "import math\n",
        "from pathlib import Path\n",
        "import geopandas as gpd\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import ee\n",
        "import datetime\n",
        "import sys\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Feature collection and output folder\n",
        "features = 'projects/remote-sensing-420704/assets/Waterbodies_qld_constructed'\n",
        "output = '/remote-sensing-420704/assets/output'\n",
        "drive =  '/remote-sensing-420704'\n",
        "\n",
        "### Date range\n",
        "# Start of analysis period, YYYY-MM-DD\n",
        "sDate = \"2024-01-01\"\n",
        "# End of analysis period, YYYY-MM-DD\n",
        "eDate = \"2024-01-31\"\n",
        "\n",
        "### Other\n",
        "# The Field with the identifier\n",
        "uniqueid_field = \"pfi\"\n",
        "# The most appropriate UTM zone for spatial analysis\n",
        "utmZoneInfo = \"EPSG:28356\"#z56\n",
        "#utmZoneInfo = \"EPSG:28355\"#z55\n",
        "#utmZoneInfo = \"EPSG:28354\"#z54\n",
        "#Index threshold Values for area (greater than or equal to)\n",
        "mdwiThresh = 0.0\n",
        "# Cloud filter percentage eg. 60%\n",
        "CLOUD_FILTER = 60\n",
        "# Other variables\n",
        "CLD_PRB_THRESH = 50\n",
        "NIR_DRK_THRESH = 0.15\n",
        "CLD_PRJ_DIST = 1\n",
        "BUFFER = 50\n",
        "BUFFERSMALL = 5\n",
        "# Create variables for field names\n",
        "dateString = \"date\"\n",
        "totAreaString = \"total_area\"\n",
        "mdwiAreaString = \"mdwi_area\"\n",
        "mdwiAvgString = \"mdwi_avg\"\n",
        "cloudAreaString = \"cloud_area\"\n",
        "mdwiPercString = \"mdwi_perc\"\n",
        "cloudPercString = \"cloud_perc\""
      ],
      "metadata": {
        "id": "L4qdcDdQH5hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project=drive)"
      ],
      "metadata": {
        "id": "g4OCOVBnmxht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the google drive\n",
        "drive.mount('/remote-sensing-420704')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0BYg9siUD5f",
        "outputId": "3bf33143-ea54-49d4-849e-07e777617f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /remote-sensing-420704; to attempt to forcibly remount, call drive.mount(\"/remote-sensing-420704\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate MNDWI.\n",
        "def calculate_mndwi(image):\n",
        "    return image.normalizedDifference(['green', 'swir1']).rename('MNDWI')\n",
        "\n",
        "# Function to iterate over the ImageCollection for a single feature and reduce it to a list of MNDWI values.\n",
        "def feature_mndwi_timeseries(feature):\n",
        "    def reduce_image(image):\n",
        "        reduction = image.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=feature.geometry(),\n",
        "            scale=30 # Adjust scale if necessary for your application\n",
        "        )\n",
        "        return ee.Feature(None, {\n",
        "            'MNDWI': reduction.get('MNDWI'),\n",
        "            'date': image.date().format()\n",
        "        })\n",
        "    timeseries = mndwi_collection.map(reduce_image)\n",
        "    return timeseries.flatten()\n",
        "\n",
        "# Function to export the results to Google Drive.\n",
        "def export_to_drive(feature_collection, batch_index):\n",
        "    task = ee.batch.Export.table.toDrive(\n",
        "        collection=feature_collection,\n",
        "        description=f'MNDWI_Timeseries_Batch_{batch_index}',\n",
        "        folder='GEE_MNDWI_Timeseries',\n",
        "        fileNamePrefix=f'mndwi_timeseries_batch_{batch_index}',\n",
        "        fileFormat='CSV'\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
        "    # Import and filter S2 SR.\n",
        "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "        .filterBounds(aoi.geometry())\n",
        "        .filterDate(start_date, end_date))\n",
        "        #.filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
        "\n",
        "    # Import and filter s2cloudless.\n",
        "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "        .filterBounds(aoi.geometry())\n",
        "        .filterDate(start_date, end_date))\n",
        "\n",
        "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
        "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
        "        'primary': s2_sr_col,\n",
        "        'secondary': s2_cloudless_col,\n",
        "        'condition': ee.Filter.equals(**{\n",
        "            'leftField': 'system:index',\n",
        "            'rightField': 'system:index'\n",
        "        })\n",
        "    }))\n",
        "\n",
        "def add_required_bands(img):\n",
        "    mndwi = img.normalizedDifference(['B3','B12']).rename('mndwi')\n",
        "\n",
        "    #Add our bands to the original collection\n",
        "    return img.addBands(ee.Image(mndwi))\n",
        "\n",
        "def add_cloud_bands(img):\n",
        "    # Get s2cloudless image, subset the probability band.\n",
        "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "\n",
        "    # Condition s2cloudless by the probability threshold value.\n",
        "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
        "\n",
        "    # Add the cloud probability layer and cloud mask as image bands.\n",
        "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
        "\n",
        "def add_shadow_bands(img):\n",
        "    # Identify water pixels from the SCL band.\n",
        "    not_water = img.select('SCL').neq(6)\n",
        "\n",
        "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
        "    SR_BAND_SCALE = 1e4\n",
        "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
        "\n",
        "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
        "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
        "\n",
        "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
        "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
        "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
        "        .select('distance')\n",
        "        .mask()\n",
        "        .rename('cloud_transform'))\n",
        "\n",
        "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
        "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
        "\n",
        "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
        "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
        "\n",
        "def add_cld_shdw_mask(img):\n",
        "    # Add the required bands to the image\n",
        "    addReqBands = add_required_bands(img)\n",
        "\n",
        "    # Add cloud component bands.\n",
        "    img_cloud = add_cloud_bands(addReqBands)\n",
        "\n",
        "    # Add cloud shadow component bands.\n",
        "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
        "\n",
        "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
        "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0).rename('cloudandshadow')\n",
        "\n",
        "    #Rob thinks this is cutting out too much cloud....\n",
        "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
        "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
        "    is_cld_shdw_FB = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20}))\n",
        "\n",
        "    is_cld_shdw_Buff = (is_cld_shdw.focalMax(BUFFERSMALL*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20}))\n",
        "\n",
        "    is_cld_shdw_FB = is_cld_shdw_FB.rename('cloudandshadowfiltbuff')\n",
        "    is_cld_shdw_Buff = is_cld_shdw_Buff.rename('cloudandshadowbuff')\n",
        "\n",
        "    # Add the final cloud-shadow mask to the image.\n",
        "    return img_cloud_shadow.addBands(ee.Image([is_cld_shdw, is_cld_shdw_FB, is_cld_shdw_Buff]))\n",
        "\n",
        "def calc_stats_from_layers(col, AOI, json_storages, utmZoneInfo, mndwiMaskVal):\n",
        "    # Convert the mask value to a float\n",
        "    mndwiMaskVal = float(mndwiMaskVal)\n",
        "\n",
        "    # Mosaic the image collection.\n",
        "    print(\"Mosaicing images\")\n",
        "    img = col.mosaic()\n",
        "\n",
        "    # Subset the cloudandshowbuff layer and create a mask where values are greater than 0\n",
        "    cloudandshadowbuff = img.select('cloudandshadowbuff').selfMask()\n",
        "\n",
        "    # Create a mask layer from the MNDWI\n",
        "    mndwi = img.select('mndwi')#.reproject(crs=utmZoneInfo['crs'], scale=utmZoneInfo['scale'])\n",
        "    mndwiMaskLayer = mndwi.gte(mndwiMaskVal).rename('mndwiMaskLayer')\n",
        "\n",
        "    # Perform reprojections\n",
        "    print(\"Clipping images\")\n",
        "    mndwiProj = mndwi.clip(AOI)#.reproject(crs=utmZoneInfo, scale=10)#Chosen 10 metres, , crsTransform='null'\n",
        "    mndwiMaskedProj = mndwiMaskLayer.clip(AOI)#.reproject(crs=utmZoneInfo, scale=10)\n",
        "    cloudandshadowbuffProj = cloudandshadowbuff.clip(AOI)#.reproject(crs=utmZoneInfo, scale=10)\n",
        "\n",
        "    #This will now give each cell in the mask area 1 * pixel area\n",
        "    #Need one complete raster for total area stats calc\n",
        "    print(\"Calculating area\")\n",
        "    allStatsLayer = mndwiProj.gte(-50.0).multiply(ee.Image.pixelArea()).rename('allPixels')\n",
        "    mndwiStatsLayer = mndwiMaskedProj.multiply(ee.Image.pixelArea()).rename('mndwiStatsLayer')\n",
        "    cloudStatsLayer = cloudandshadowbuffProj.multiply(ee.Image.pixelArea()).rename('cloudStatsLayer')\n",
        "\n",
        "    # Create a collection of features\n",
        "    #theCollection = ee.FeatureCollection(json_storages)\n",
        "\n",
        "    # Calculate statistics using the reducer\n",
        "    print(\"Calculating stats\")\n",
        "    allStats = allStatsLayer.reduceRegions(**{'reducer': ee.Reducer.sum(),'crs':utmZoneInfo, 'scale': 10,'collection': col}).getInfo()['features']\n",
        "    mndwiStats = mndwiStatsLayer.reduceRegions(**{'reducer': ee.Reducer.sum(),'crs':utmZoneInfo, 'scale': 10,'collection': col}).getInfo()['features']\n",
        "    cloudStats = cloudStatsLayer.reduceRegions(**{'reducer': ee.Reducer.sum(),'crs':utmZoneInfo, 'scale': 10,'collection': col}).getInfo()['features']\n",
        "\n",
        "    #Send back a dictionary of JSON objects, these string identifiers will need to be match in the script that calls this function\n",
        "    return {'allAreas':allStats,'mndwiAreas':mndwiStats,'cloudAreas':cloudStats}\n",
        "\n",
        "def retrieveStatsFromJSON(theResultsDict, theIDField, theMetric, theDataPropertyName):\n",
        "    # Create a dataframe to store results\n",
        "    geeStats = pd.DataFrame(columns=[theIDField, theDataPropertyName])\n",
        "\n",
        "    # Add each row to the dataframe\n",
        "    for i in range(len(theResultsDict)):\n",
        "        theID = theResultsDict[i][\"properties\"][theIDField]\n",
        "        dataRow = [theID, -9999]\n",
        "\n",
        "        # Apply the calculation if required eg. Sum\n",
        "        if theMetric in theResultsDict[i][\"properties\"]:\n",
        "            dataRow = [theID, theResultsDict[i][\"properties\"][theMetric]]\n",
        "\n",
        "        # Add the results to the dataframe row\n",
        "        geeStats.loc[len(geeStats)] = dataRow\n",
        "\n",
        "    return geeStats\n",
        "\n",
        "def process_batch(batch):\n",
        "    # Convert the batch to a list of ee.Features.\n",
        "    features = []\n",
        "    for _, row in batch.iterrows():\n",
        "        geom = ee.Geometry.Polygon(row['geometry'].exterior.coords)\n",
        "        feature = ee.Feature(geom, row.drop('geometry').to_dict())\n",
        "        features.append(feature)\n",
        "\n",
        "    # Create a FeatureCollection from the features list.\n",
        "    batch_feature_collection = ee.FeatureCollection(features)\n",
        "\n",
        "    # Here you can add processing specific to the batch.\n",
        "    # For example, printing the size of the batch.\n",
        "    print('Processed batch with feature count:', batch_feature_collection.size().getInfo())\n",
        "\n",
        "def batch_process_shapefile(gdf, batch_size):\n",
        "    for index in range(0, len(gdf), batch_size):\n",
        "        batch = gdf.iloc[index:index + batch_size]\n",
        "        process_batch(batch)"
      ],
      "metadata": {
        "id": "21cZZdZ0mxwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# For a FeatureCollection (like a shapefile or table)\n",
        "all_features = ee.FeatureCollection(features)"
      ],
      "metadata": {
        "id": "q0tCV28Pmx2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = all_features.size().getInfo()\n",
        "print(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N64NQhplmyDZ",
        "outputId": "7eafdd56-555b-447d-c3ea-0ffe262eb376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dates to the correct format\n",
        "overallStartDate = datetime.datetime.strptime(sDate,\"%Y-%m-%d\")\n",
        "overallEndDate = datetime.datetime.strptime(eDate,\"%Y-%m-%d\")\n",
        "\n",
        "# Count the number of days to process\n",
        "delta = overallEndDate - overallStartDate\n",
        "theDayCount = delta.days + 1\n",
        "print(\"Total days:\", theDayCount)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnsxKPPVHz1d",
        "outputId": "4da05812-fb5b-465e-fd32-90d0faad77ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total days: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basin = 'Burdekin'\n",
        "query = 'drainage_b == \"{}\"'.format(basin)\n",
        "print(query)\n",
        "\n",
        "fc_server = all_features.filter(query)\n",
        "\n",
        "size = fc_server.size().getInfo()\n",
        "print(size)\n",
        "\n",
        "\n",
        "# This will give bounds in expected GEE format\n",
        "geeFeatureGeometry = ee.Geometry(fc_server.geometry())\n",
        "AOI = geeFeatureGeometry.bounds()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0PZK-aLJ6zE",
        "outputId": "e0d75d47-ac28-4a8c-ea0c-4cb5311600aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drainage_b == \"Burdekin\"\n",
            "2332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty dataframe for results\n",
        "tsStats = pd.DataFrame(columns=[uniqueid_field, dateString, totAreaString, mdwiAreaString, cloudAreaString, mdwiPercString, cloudPercString])\n",
        "\n",
        "# Get current time\n",
        "beginNow = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
        "print(\"Starting at \" + beginNow)\n",
        "print(\"\")\n",
        "\n",
        "# For each day\n",
        "for i in range(theDayCount):\n",
        "\n",
        "    # Get the date range\n",
        "    theStartDate = overallStartDate + datetime.timedelta(days=i)\n",
        "    theStart = datetime.datetime.strftime(theStartDate, \"%Y-%m-%d\")\n",
        "    theEndDate = overallStartDate + datetime.timedelta(days=i+1)\n",
        "    theEnd = datetime.datetime.strftime(theEndDate, \"%Y-%m-%d\")\n",
        "\n",
        "    # Create a dataframe to store daily results\n",
        "    dfCombo = pd.DataFrame()\n",
        "\n",
        "    # Print the current time\n",
        "    hereNow = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
        "    print(\"Processing period: \" + str(theStart) + \" at \" + hereNow)\n",
        "\n",
        "    # Create an image collection\n",
        "    theImgColl = get_s2_sr_cld_col(fc_server, theStart, theEnd)\n",
        "    print(int(theImgColl.size().getInfo()))\n",
        "    numElements = theImgColl.size().getInfo()\n",
        "\n",
        "    # If images are found for that day\n",
        "    if numElements > 0:\n",
        "\n",
        "        # Print the number of images found\n",
        "        print(\"Images found: \" + str(numElements))\n",
        "\n",
        "        # Add cloud shadow mask\n",
        "        print(\"Adding shadow mask\")\n",
        "        theImgCollExpanded = theImgColl.map(add_cld_shdw_mask)\n",
        "\n",
        "        # Calculate stats from layers\n",
        "        print(\"Calculating stats\")\n",
        "        statsDict = calc_stats_from_layers(theImgCollExpanded, geeFeatureGeometry, fc_server, utmZoneInfo, mdwiThresh)\n",
        "\n",
        "        # Retrieve stats for allAreas\n",
        "        print(\"Retrieving stats\")\n",
        "        dfAll = retrieveStatsFromJSON(statsDict[\"allAreas\"], uniqueid_field, \"sum\", totAreaString)\n",
        "\n",
        "        # Add date column\n",
        "        dfAll[dateString] = theStart\n",
        "\n",
        "        # Retrieve stats for MDWI and Clouds\n",
        "        dfMDWI = retrieveStatsFromJSON(statsDict[\"mndwiAreas\"], uniqueid_field, \"sum\", mdwiAreaString)\n",
        "        dfCloud = retrieveStatsFromJSON(statsDict[\"cloudAreas\"], uniqueid_field, \"sum\", cloudAreaString)\n",
        "\n",
        "        # Merge all of the DF's together\n",
        "        dfCombo = pd.merge(dfAll, dfMDWI, how=\"left\", left_on=[uniqueid_field], right_on=[uniqueid_field])\n",
        "        dfCombo = pd.merge(dfCombo, dfCloud, how=\"left\", left_on=[uniqueid_field], right_on=[uniqueid_field])\n",
        "\n",
        "        # Add the percentage fields\n",
        "        dfCombo[mdwiPercString] = dfCombo.apply(lambda row: (row[mdwiAreaString] / row[totAreaString]) * 100 if row[totAreaString] != 0 else 0, axis=1)\n",
        "        dfCombo[cloudPercString] = dfCombo.apply(lambda row: (row[cloudAreaString] / row[totAreaString]) * 100 if row[totAreaString] != 0 else 0, axis=1)\n",
        "\n",
        "        # Add stats to the results dataframe\n",
        "        if len(dfCombo) > 0:\n",
        "            tsStats = pd.concat([tsStats, dfCombo])\n",
        "\n",
        "        # Print the finish time for the day\n",
        "        hereNow = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
        "        print(\"Done processing day: \" + str(theStart) + \" at \" + hereNow)\n",
        "        print(\"\")\n",
        "\n",
        "    else:\n",
        "        # Print the finish time for the day\n",
        "        print(\"No images found\")\n",
        "        print(\"\")\n",
        "\n",
        "# Save total results to CSV\n",
        "file_path = folder_path + basin\n",
        "tsStats.to_csv(file_path, index=False)\n",
        "\n",
        "# Calculate time taken for completion\n",
        "rightNow = datetime.datetime.now().strftime(\"%d/%m/%Y, %H:%M:%S\")\n",
        "print(\"Entire period processed, started at \" + beginNow + \" and finished at \" + rightNow)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "A8Rwyt0GIgYb",
        "outputId": "4d6bacc3-d7c6-42d8-8378-03af2ccbe566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting at 04/06/2024, 06:04:07\n",
            "\n",
            "Processing period: 2024-01-01 at 04/06/2024, 06:04:07\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can only concatenate str (not \"module\") to str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-c95ffb2c91fb>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Create an image collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtheImgColl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_s2_sr_cld_col\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_server\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheEnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheImgColl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mnumElements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheImgColl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/computedobject.py\u001b[0m in \u001b[0;36mgetInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mto\u001b[0m \u001b[0manything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/data.py\u001b[0m in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1108\u001b[0m       \u001b[0m_get_cloud_projects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m       \u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_projects_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprettyPrint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m   )['result']\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ee/data.py\u001b[0m in \u001b[0;36m_get_projects_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    306\u001b[0m   \u001b[0;34m\"\"\"Returns the projects path to use for constructing a request.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_cloud_api_user_project\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'projects/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_cloud_api_user_project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'projects/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDEFAULT_CLOUD_API_USER_PROJECT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"module\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6lt0tihY1kGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tdISVBRe1kNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yWOB8zsZUZyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}