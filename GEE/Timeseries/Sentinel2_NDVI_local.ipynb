{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "storage_shapefile = \"BR_Sample_Parcels_proj.shp\"\n",
    "storage_id_field = \"qldglobe_p\"\n",
    "\n",
    "# Output files\n",
    "outputCSV = \"GEE_Map_Cropping_Sentinel.csv\"\n",
    "\n",
    "# Cloud cover\n",
    "CLOUD_FILTER = 0 # Under 40%\n",
    "\n",
    "# Thresholds\n",
    "ndwiMaskVal = -0.1\n",
    "ndviMaskVal = 0.5\n",
    "\n",
    "# UTM Zone\n",
    "utmZoneInfo = 'EPSG:28355'#z55S\n",
    "\n",
    "# Dates\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2022-01-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ee, geemap, folium, pandas, geopandas as gpd, json, datetime, altair as alt, csv\n",
    "from IPython.display import Image\n",
    "import ee.mapclient\n",
    "import datetime\n",
    "import os\n",
    "from os.path import exists as file_exists\n",
    "\n",
    "import requests\n",
    "\n",
    "# importing pandas as pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_api():\n",
    "    dem = ee.Image('USGS/SRTMGL1_003')\n",
    "    xy = ee.Geometry.Point([86.9250, 27.9881])\n",
    "    elev = dem.sample(xy, 30).first().get('elevation').getInfo()\n",
    "    print('Authentication active')\n",
    "\n",
    "def addDate(image):\n",
    "    # parse date stored in 'system:index'\n",
    "    date = ee.Date(image.get('system:index'))\n",
    "\n",
    "    # format date, see http:#www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\n",
    "    str = date.format('YYYY-mm-dd')\n",
    "\n",
    "    return image.set({'Date': str})\n",
    "\n",
    "def mean_func(image):\n",
    "    mean = (image                        \n",
    "            #.mean()\n",
    "            .reduceRegion(ee.Reducer.mean()))#, storage_geometry, 30))\n",
    "    mean = mean.getInfo()            \n",
    "    mean = mean.get('nd')    \n",
    "    return mean\n",
    "\n",
    "def test_api():\n",
    "    dem = ee.Image('USGS/SRTMGL1_003')\n",
    "    xy = ee.Geometry.Point([86.9250, 27.9881])\n",
    "    elev = dem.sample(xy, 30).first().get('elevation').getInfo()\n",
    "    print('Authentication active')\n",
    "    \n",
    "def transformer(feature):\n",
    "    transformed_feature = feature.transform(utmZoneInfo, 0.001);\n",
    "    return transformed_feature;\n",
    "\n",
    "def filterImages(storage_geometry):\n",
    "    # Load Sentinel2\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(storage_geometry)\n",
    "        .filterDate(start_date, end_date))\n",
    "        #.filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "    \n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(storage_geometry)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }));\n",
    "\n",
    "\n",
    "\n",
    "def exportStats(lot):\n",
    "    # Create a new dataframe\n",
    "    storageStats = pandas.DataFrame(columns=['Lotplan', 'Date', 'Total Area', 'Veg Area', 'Cloud Cover'])        \n",
    "    # Select the feature\n",
    "    storage_selection = storage_collection.filter(ee.Filter.eq(storage_id_field, lot))   \n",
    "    # Get the geometry\n",
    "    storage_geometry = storage_selection.geometry()\n",
    "    # Create list of images\n",
    "    images = filterImages(storage_geometry)\n",
    "    # Clip images to storage and reproject\n",
    "    images = images.map(lambda image: image.clip(storage_geometry).reproject(crs=utmZoneInfo))\n",
    "    # Create a list of images\n",
    "    imageSize = images.size().getInfo()    \n",
    "    imageList = images.toList(images.size()) \n",
    "    # Get stats ##\n",
    "    # For each image\n",
    "    for img in range(0, imageSize):    \n",
    "        # Choose the image\n",
    "        image = ee.Image(imageList.get(img))\n",
    "        # Get date\n",
    "        date = ee.Date(image.get('system:time_start')).format(\"yyyy-MM-dd\")\n",
    "        date = date.getInfo()\n",
    "        print(date)\n",
    "        # Create images\n",
    "        ndvi = image.normalizedDifference(['B8', 'B4'])\n",
    "        ndviMaskLayer = ndvi.gte(ndviMaskVal).rename('ndviMaskLayer')\n",
    "        #This would retain values of NDWI, not set them to 0/1\n",
    "        ndvimasked = ndvi.updateMask(ndviMaskLayer)#.rename('ndwi')\n",
    "        #Need one complete raster for total area stats calc\n",
    "        ndviProj = ndvi.reproject(crs=utmZoneInfo, scale=10)#Chosen 10 metres, , crsTransform='null'\n",
    "        ndviMaskedProj = ndviMaskLayer.reproject(crs=utmZoneInfo, scale=10)\n",
    "        storage_area = ndviProj.gte(-50.0).multiply(ee.Image.pixelArea()).rename('allPixels')\n",
    "        veg_area = ndviMaskedProj.multiply(ee.Image.pixelArea()).rename('ndwiStatsLayer')\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        # Get cloud cover\n",
    "        cloudiness = image.get(\"CLOUD_COVER\").getInfo()\n",
    "        # Add results to storage stats dataframe\n",
    "        results = [lot,date,storage_area,veg_area,cloudiness]\n",
    "        print(results)\n",
    "        storageStats.loc[len(storageStats)] = results  \n",
    "        storageStatsMaster.loc[len(storageStats)] = results   \n",
    "        # Export image\n",
    "        #exportRGBImage(image)\n",
    "    # Save to CSV\n",
    "    storageStats.to_csv(outputCSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate Earth Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication active\n"
     ]
    }
   ],
   "source": [
    "# Test access then authenticate if fails\n",
    "try:\n",
    "    test_api()\n",
    "except:    \n",
    "    ee.Authenticate()\n",
    " \n",
    "# Initialize the library.\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert shapefile into feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ee.featurecollection.FeatureCollection at 0x2098a9ae760>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load shapefile into geopandas\n",
    "storage_shapes = gpd.read_file(storage_shapefile)\n",
    "\n",
    "# Convert shapes into json\n",
    "json_storages = json.loads(storage_shapes.to_json())\n",
    "\n",
    "# Convert json into feature collection\n",
    "storage_collection =  ee.FeatureCollection(json_storages)\n",
    "\n",
    "# Reproject collection\n",
    "#storage_collection = storage_collection.map(transformer);\n",
    "\n",
    "# Add area\n",
    "storage_collection.map(lambda feature: feature.set('total_area', ee.Number(feature.area()).divide(1e6).round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of Storage IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['101SP207166', '108SP207166', '110F6901', '111F6901', '11RP218867', '14CVN407', '15CVN386', '16BLM76', '17CVN407', '1BLM66', '1BLM846', '1PER4265', '1RP225469', '1SP132773', '236RP851344', '23SP225448', '24PG406', '25PG260', '297SP146073', '2BLM1', '2BLM465', '2SP276749', '31BLM809', '33CP849174', '39BLM782', '3BLM1', '3RP225469', '3SP276749', '4BEL5359', '4SP276749', '5RP212965', '5RP213579', '5SP225462', '5SP276749', '612RP909550', '62SP225462', '63CP858891', '6RP213579', '71RP213572', '73RP213572', '7BLM715', '8CVN140', 'AAP21199']\n"
     ]
    }
   ],
   "source": [
    "# list the unique quality code values\n",
    "worksSet = sorted(storage_shapes[storage_id_field].unique())\n",
    "print(worksSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip imagery to each storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at 2023-03-03 14:08:59.960408\n",
      "Starting 101SP207166\n",
      "2022-01-01\n",
      "['101SP207166', '2022-01-01', <ee.image.Image object at 0x000002098A603490>, <ee.image.Image object at 0x0000020989C2D790>, None]\n",
      "2022-01-01\n",
      "['101SP207166', '2022-01-01', <ee.image.Image object at 0x000002098A16A220>, <ee.image.Image object at 0x000002098A16A910>, None]\n",
      "2022-01-01\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe\n",
    "storageStatsMaster = pandas.DataFrame(columns=['Lotplan', 'Date', 'Total Area', 'Veg Area', 'Cloud Cover'])  \n",
    "\n",
    "# Start timer\n",
    "startNow = datetime.datetime.now()\n",
    "print(\"Starting at \" + str(startNow))\n",
    "\n",
    "# For each storage\n",
    "for worksNumber in worksSet:\n",
    "    \n",
    "    # Create file name for csv export\n",
    "    outputCSV = worksNumber + \"_Sentinel_Timeseries.csv\"\n",
    "    \n",
    "    # Check if already completed\n",
    "    if file_exists(outputCSV):\n",
    "        \n",
    "        print(\"Skipping \" + worksNumber)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Create an image function to map\n",
    "        print(\"Starting \" + worksNumber)\n",
    "        exportStats(worksNumber)\n",
    "        \n",
    "\n",
    "# Save master     \n",
    "storageStats.to_csv(outputCSV)\n",
    "        \n",
    "# Print the storage stats\n",
    "print(\"Finished\")\n",
    "\n",
    "# Finish time\n",
    "endNow = datetime.datetime.now()\n",
    "diff = (endNow-startNow).total_seconds()\n",
    "print(\"End at \" + str(endNow))\n",
    "print(\"Taking: \" + str(diff) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
